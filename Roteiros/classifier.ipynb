{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrindo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(filter(lambda x: x.endswith('pkl'), os.listdir()))\n",
    "features = ['sobel', 'glcm', 'lbp']\n",
    "datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    datasets[file.split('.')[0]] = pd.read_pickle(file)\n",
    "\n",
    "for dataset in datasets.keys():\n",
    "    datasets[dataset] = datasets[dataset].sort_values('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unindo as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.column_stack([datasets[x][y].tolist() for x in datasets.keys() for y in features]), datasets['gaussian']['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811 158319 (811, 158319) (811,)\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(X[0]), X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 100 22500\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets['gaussian']['lbp'][0].tolist()),len(datasets['gaussian']['glcm'][0].tolist()),len(datasets['gaussian']['sobel'][0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158319"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(17+100+22500)*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedKFold para dividir os conjuntos de treino / teste  - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.46      0.47       155\n",
      "           1       0.68      0.70      0.69       251\n",
      "\n",
      "    accuracy                           0.61       406\n",
      "   macro avg       0.58      0.58      0.58       406\n",
      "weighted avg       0.60      0.61      0.60       406\n",
      "\n",
      "\n",
      "rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       155\n",
      "           1       0.62      1.00      0.76       251\n",
      "\n",
      "    accuracy                           0.62       406\n",
      "   macro avg       0.31      0.50      0.38       406\n",
      "weighted avg       0.38      0.62      0.47       406\n",
      "\n",
      "\n",
      "poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.05      0.09       155\n",
      "           1       0.62      0.97      0.76       251\n",
      "\n",
      "    accuracy                           0.62       406\n",
      "   macro avg       0.58      0.51      0.43       406\n",
      "weighted avg       0.59      0.62      0.51       406\n",
      "\n",
      "\n",
      "1\n",
      "linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.59      0.51       145\n",
      "           1       0.73      0.60      0.66       260\n",
      "\n",
      "    accuracy                           0.60       405\n",
      "   macro avg       0.59      0.60      0.59       405\n",
      "weighted avg       0.63      0.60      0.61       405\n",
      "\n",
      "\n",
      "rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.10       145\n",
      "           1       0.65      0.97      0.78       260\n",
      "\n",
      "    accuracy                           0.64       405\n",
      "   macro avg       0.57      0.51      0.44       405\n",
      "weighted avg       0.59      0.64      0.53       405\n",
      "\n",
      "\n",
      "poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.17      0.25       145\n",
      "           1       0.66      0.90      0.76       260\n",
      "\n",
      "    accuracy                           0.64       405\n",
      "   macro avg       0.57      0.53      0.51       405\n",
      "weighted avg       0.60      0.64      0.58       405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    print(i)\n",
    "    for kernel in ['linear', 'rbf', 'poly']:\n",
    "        svm = SVC(random_state=42, kernel=kernel)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_hat = svm.predict(X_test)\n",
    "        print(kernel)\n",
    "        print(classification_report(y_test, y_hat))\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "identity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       155\n",
      "           1       0.62      1.00      0.76       251\n",
      "\n",
      "    accuracy                           0.62       406\n",
      "   macro avg       0.31      0.50      0.38       406\n",
      "weighted avg       0.38      0.62      0.47       406\n",
      "\n",
      "\n",
      "logistic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       155\n",
      "           1       0.62      1.00      0.76       251\n",
      "\n",
      "    accuracy                           0.62       406\n",
      "   macro avg       0.31      0.50      0.38       406\n",
      "weighted avg       0.38      0.62      0.47       406\n",
      "\n",
      "\n",
      "tanh\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.28      0.35       155\n",
      "           1       0.64      0.78      0.70       251\n",
      "\n",
      "    accuracy                           0.59       406\n",
      "   macro avg       0.54      0.53      0.52       406\n",
      "weighted avg       0.56      0.59      0.56       406\n",
      "\n",
      "\n",
      "relu\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       155\n",
      "           1       0.62      1.00      0.76       251\n",
      "\n",
      "    accuracy                           0.62       406\n",
      "   macro avg       0.31      0.50      0.38       406\n",
      "weighted avg       0.38      0.62      0.47       406\n",
      "\n",
      "\n",
      "1\n",
      "identity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.74      0.62       145\n",
      "           1       0.81      0.64      0.72       260\n",
      "\n",
      "    accuracy                           0.67       405\n",
      "   macro avg       0.67      0.69      0.67       405\n",
      "weighted avg       0.71      0.67      0.68       405\n",
      "\n",
      "\n",
      "logistic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       145\n",
      "           1       0.64      1.00      0.78       260\n",
      "\n",
      "    accuracy                           0.64       405\n",
      "   macro avg       0.32      0.50      0.39       405\n",
      "weighted avg       0.41      0.64      0.50       405\n",
      "\n",
      "\n",
      "tanh\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       145\n",
      "           1       0.64      1.00      0.78       260\n",
      "\n",
      "    accuracy                           0.64       405\n",
      "   macro avg       0.32      0.50      0.39       405\n",
      "weighted avg       0.41      0.64      0.50       405\n",
      "\n",
      "\n",
      "relu\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       145\n",
      "           1       0.64      1.00      0.78       260\n",
      "\n",
      "    accuracy                           0.64       405\n",
      "   macro avg       0.32      0.50      0.39       405\n",
      "weighted avg       0.41      0.64      0.50       405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    print(i)\n",
    "    for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "        mlp = MLPClassifier(random_state=42, max_iter=200,early_stopping=True, activation=activation)\n",
    "\n",
    "        mlp.fit(X_train, y_train)\n",
    "        y_hat = mlp.predict(X_test)\n",
    "        print(activation)\n",
    "        print(classification_report(y_test, y_hat))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c67a77925574e256ea3d3ec23d2fa92ea6ae9fcaff584ba484978fc88efa5070"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('cvision': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
